{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cooperative_client.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPAfLmkZWo3AjFOWdZ3sQuk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MauriVass/MachineLearningInIoT_HWs/blob/mauri/HM3/Exercise2/notebook/inference_client.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyIDOWiW8M6r"
      },
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\r\n",
        "!pip install pyaudio\r\n",
        "!pip install paho-mqtt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmkxg9k68AzR"
      },
      "source": [
        "import time\r\n",
        "import sys\r\n",
        "import json\r\n",
        "import pyaudio\r\n",
        "import datetime\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import base64\r\n",
        "\r\n",
        "import os\r\n",
        "if(os.path.exists('Temp')==False):\r\n",
        "  !git clone https://github.com/MauriVass/Temp.git\r\n",
        "\r\n",
        "path = './Temp/ML4IoT/'\r\n",
        "sys.path.insert(0, path)\r\n",
        "from DoSomething import DoSomething\r\n",
        "\r\n",
        "class Receiver(DoSomething):\r\n",
        "  def __init__(self,clientID, model):\r\n",
        "    super().__init__(clientID)\r\n",
        "    self.model = model\r\n",
        "\r\n",
        "  def notify(self, topic, msg):\r\n",
        "    # print(topic, msg)\r\n",
        "    r = msg.decode('utf-8')\r\n",
        "    r = json.loads(r)\r\n",
        "    if('e' not in r):\r\n",
        "      print(\"ANSWER PROBLEMS!! REQUIRED AN EVENT. RECEIVED:\", r, ' CLOSING APPLICATION!')\r\n",
        "\t\t\texit()\r\n",
        "    events = r['e']\r\n",
        "    if('vd' not in events[0]):\r\n",
        "      print(\"ANSWER PROBLEMS!! REQUIRED AN AUDIO FILE. RECEIVED:\", events[0], ' CLOSING APPLICATION!')\r\n",
        "\t\t\texit()\r\n",
        "    audio = events[0]['vd']\r\n",
        "\r\n",
        "    audio_bytes = audio.encode()\r\n",
        "    audio_bytes = base64.b64decode(audio_bytes)\r\n",
        "    data = tf.io.decode_raw(audio_bytes,tf.float32)\r\n",
        "    dims =  [49,10,1]\r\n",
        "    data = tf.reshape(data,dims)\r\n",
        "    data = tf.expand_dims(data,0)\r\n",
        "\r\n",
        "    prediction = self.model.Evaluate(data)\r\n",
        "    prediction = tf.nn.softmax(prediction)\r\n",
        "    prediction = np.argmax(prediction)\r\n",
        "\r\n",
        "    if('id' not in events[0]):\r\n",
        "      print(\"ANSWER PROBLEMS!! REQUIRED AN ID. RECEIVED:\", events[0], ' CLOSING APPLICATION!')\r\n",
        "\t\t\texit()\r\n",
        "    id = str(events[0]['id'])\r\n",
        "    # timestamp = int(datetime.datetime.now().timestamp())\r\n",
        "    body = { 'id': id, 'prediction':str(prediction)  }\r\n",
        "    #print(body)\r\n",
        "    body = json.dumps(body)\r\n",
        "    self.myMqttClient.myPublish(idtopic+self.clientID+\"/prediction/\" ,body ,False)\r\n",
        "\r\n",
        "class Model:\r\n",
        "  def __init__(self, model_path):\r\n",
        "    self.model_path = model_path\r\n",
        "\r\n",
        "    if(model_path.find('zlib')>0):\r\n",
        "      raise KeyError('YOU CAN\\'T TEST A .zlib MODEL. (Use zipping=False in Optimize() method)')\r\n",
        "    self.interpreter = tf.lite.Interpreter(model_path=model_path)\r\n",
        "    self.interpreter.allocate_tensors()\r\n",
        "\r\n",
        "    self.input_details = self.interpreter.get_input_details()\r\n",
        "    self.output_details = self.interpreter.get_output_details()\r\n",
        "\r\n",
        "  def Evaluate(self,input_data):\r\n",
        "    self.interpreter.set_tensor(self.input_details[0]['index'], input_data)\r\n",
        "    self.interpreter.invoke()\r\n",
        "    output = self.interpreter.get_tensor(self.output_details[0]['index'])[0]\r\n",
        "    return output\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IGc44jR8HgP"
      },
      "source": [
        "if __name__ == \"__main__\":\r\n",
        "  model_path = ''\r\n",
        "  model = Model(model_path)\r\n",
        "\r\n",
        "  name_server = \"InferClient\"\r\n",
        "  coop_client = Receiver(name_server, model)\r\n",
        "  coop_client.run()\r\n",
        "  idtopic = '/Group14_ML4IoT/'\r\n",
        "  coop_client.myMqttClient.mySubscribe(idtopic+'audio/')\r\n",
        "\r\n",
        "  a=0\r\n",
        "  while (True): #Find a better way\r\n",
        "    a+=1\r\n",
        "    time.sleep(1)\r\n",
        "\r\n",
        "  coop_client.end()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr60DroASc4l"
      },
      "source": [
        "coop_client.end()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YtaPpDgon_N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}