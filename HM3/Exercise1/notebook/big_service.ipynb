{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} cherrypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.lite as tflite\n",
    "import cherrypy\n",
    "import json\n",
    "import base64\n",
    "from cherrypy.process.wspbus import ChannelFailures\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "\n",
    "class FeatureExtractor:\n",
    "\n",
    "    def __init__(self, sampling_rate, frame_length, frame_step, num_mel_bins=None, lower_frequency=None,\n",
    "                 upper_frequency=None, num_coefficients=None, mfcc=False, image_size=32):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.frame_length = frame_length\n",
    "        self.frame_step = frame_step\n",
    "        self.num_mel_bins = num_mel_bins\n",
    "        self.lower_frequency = lower_frequency\n",
    "        self.upper_frequency = upper_frequency\n",
    "        self.num_coefficients = num_coefficients\n",
    "        self.mfccs = mfcc\n",
    "        self.image_size = image_size\n",
    "\n",
    "        if (mfcc):\n",
    "            num_spectrogram_bins = frame_length // 2 + 1\n",
    "            self.linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "                self.num_mel_bins,\n",
    "                num_spectrogram_bins,\n",
    "                self.sampling_rate,\n",
    "                self.lower_frequency,\n",
    "                self.upper_frequency)\n",
    "            self.preprocess = self.preprocess_with_mfcc\n",
    "        else:\n",
    "            self.preprocess = self.preprocess_with_stft\n",
    "\n",
    "    def pad(self, audio):\n",
    "        zero_padding = tf.zeros(self.sampling_rate - tf.shape(audio), dtype=tf.float32)\n",
    "        audio = tf.concat([audio, zero_padding], 0)\n",
    "        audio.set_shape([self.sampling_rate])\n",
    "        return audio\n",
    "\n",
    "    def get_spectrogram(self, audio):\n",
    "        # Calculate the STFT of the signal given frame_length and frame_step\n",
    "        stft = tf.signal.stft(audio,\n",
    "                              frame_length=self.frame_length,\n",
    "                              frame_step=self.frame_step,\n",
    "                              fft_length=self.frame_length)\n",
    "        # Transform the complex number in real number\n",
    "        spectrogram = tf.abs(stft)\n",
    "        return spectrogram\n",
    "\n",
    "    def get_mfccs(self, spectrogram):\n",
    "        mel_spectrogram = tf.tensordot(spectrogram,\n",
    "                                       self.linear_to_mel_weight_matrix, 1)\n",
    "        log_mel_spectrogram = tf.math.log(mel_spectrogram + 1.e-6)\n",
    "        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)\n",
    "        mfccs = mfccs[:, :self.num_coefficients]\n",
    "        return mfccs\n",
    "\n",
    "    def preprocess_with_stft(self, audio):\n",
    "        audio = self.pad(audio)\n",
    "        spectrogram = self.get_spectrogram(audio)\n",
    "        spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "        spectrogram = tf.image.resize(spectrogram, [self.image_size, self.image_size])\n",
    "        return spectrogram\n",
    "\n",
    "    def preprocess_with_mfcc(self, audio):\n",
    "        audio = self.pad(audio)\n",
    "        spectrogram = self.get_spectrogram(audio)\n",
    "        mfccs = self.get_mfccs(spectrogram)\n",
    "        mfccs = tf.expand_dims(mfccs, -1)\n",
    "        return mfccs\n",
    "\n",
    "    def load_audio_from_base_64(self, audio):\n",
    "        audio = base64.b64decode(audio)\n",
    "        return audio\n",
    "\n",
    "    def audio_preprocessing(self, audio):\n",
    "        try:\n",
    "            audio, _ = tf.audio.decode_wav(audio)\n",
    "            audio = tf.squeeze(audio, axis=1)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        # audio = self.load_audio_from_base_64(audio)\n",
    "        processed_audio = self.preprocess(audio)\n",
    "        return processed_audio\n",
    "\n",
    "    def load_model(self):\n",
    "        pass\n",
    "\n",
    "    def test(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, model_path):\n",
    "        self.model_path = model_path\n",
    "\n",
    "        if (model_path.find('zip') > 0):\n",
    "            raise KeyError('YOU CAN\\'T TEST A .zip MODEL. (Use zipping=False in Optimize() method)')\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "        self.interpreter.allocate_tensors()\n",
    "\n",
    "        self.input_details = self.interpreter.get_input_details()\n",
    "        self.output_details = self.interpreter.get_output_details()\n",
    "\n",
    "    def Evaluate(self, data):\n",
    "        # print(self.input_details[0]['index'])\n",
    "        # print(self.output_details[0]['index'])\n",
    "        # print(data.shape)\n",
    "        self.interpreter.set_tensor(self.input_details[0]['index'], data)\n",
    "        self.interpreter.invoke()\n",
    "        output = self.interpreter.get_tensor(self.output_details[0]['index'])[0]\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class Server(object):\n",
    "    exposed = True\n",
    "    \n",
    "    def __init__(self):\n",
    "        # It can be: True, False\n",
    "        mfcc = True\n",
    "        # It can be (0,1]\n",
    "        alpha = 1\n",
    "        # Sparcity increases latency(may be a problem for KS) due to cache misses\n",
    "        # it can be (0.3,1) or None(if you don't to use sparsity)\n",
    "        sparsity = None\n",
    "\n",
    "        # Here you can change:\n",
    "        # STFT(mfcc=False): frame_length, frame_step\n",
    "        # MFCC(mfcc=True): frame_length, frame_step, num_mel_bins, num_coefficients, lower_frequency(?), upper_frequency(?)\n",
    "        frame_length = 640  # Default 640 (mfcc=True), 256(mfcc=False)\n",
    "        frame_step = 320  # Default 320 (mfcc=True), 128(mfcc=False)\n",
    "        num_mel_bins = 40  # Default 40 (only mfcc=True)\n",
    "        num_coefficients = 10  # Default 10 (only mfcc=True)\n",
    "        image_size = 32  # Default 32 (only mfcc=False)\n",
    "\n",
    "        if (mfcc):\n",
    "            self.feature = FeatureExtractor(sampling_rate=16000, frame_length=int(frame_length),\n",
    "                                       frame_step=int(frame_step),\n",
    "                                       num_mel_bins=int(num_mel_bins), lower_frequency=20, upper_frequency=4000,\n",
    "                                       num_coefficients=int(num_coefficients), mfcc=mfcc)\n",
    "        else:\n",
    "            self.feature = FeatureExtractor(sampling_rate=16000, frame_length=frame_length, frame_step=frame_step,\n",
    "                                       image_size=image_size)\n",
    "\n",
    "\n",
    "    def request_checker(seld, input):\n",
    "        input = json.loads(input)\n",
    "        ip = None\n",
    "        timestamp = None\n",
    "        audio = None\n",
    "\n",
    "        bn = input[\"bn\"]\n",
    "\n",
    "        if input['bn'] is None:\n",
    "            raise cherrypy.HTTPError(400, \"Client IP is missing\")\n",
    "        else:\n",
    "            ip = input['bn']\n",
    "\n",
    "        if input['bi'] is None:\n",
    "            raise cherrypy.HTTPError(400, \"timestamp is missing\")\n",
    "        else:\n",
    "            timestamp = input['bi']\n",
    "\n",
    "        if input['e'] is None:\n",
    "            raise cherrypy.HTTPError(400, \"audio is missing\")\n",
    "        else:\n",
    "            e = input['e'][0]\n",
    "            audioBase64 = e['vd']\n",
    "            if audioBase64 is None:\n",
    "                raise cherrypy.HTTPError(400, \"audio base 64 format is missing\")\n",
    "            else:\n",
    "                audio = base64.b64decode(audioBase64)\n",
    "\n",
    "        return audio\n",
    "\n",
    "    def PUT(self, *path, **query):\n",
    "        input = cherrypy.request.body.read()\n",
    "        audio = self.request_checker(input)\n",
    "        \n",
    "        processed_audio = self.feature.audio_preprocessing(audio)\n",
    "        model = Model('CTrueFL640FS320NM10.tflite_W')\n",
    "        data = tf.expand_dims(processed_audio, axis=0)\n",
    "        y_pred = model.Evaluate(data)\n",
    "        y_pred = tf.nn.softmax(y_pred).numpy()\n",
    "        y_pred_best = np.argmax(y_pred)\n",
    "        print('y_pred ', y_pred_best, y_pred[y_pred_best])\n",
    "        \n",
    "        body = { 'label': str(y_pred_best), 'probability':f'{(y_pred[y_pred_best]):.4f}' }\n",
    "        return json.dumps(body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    conf = {\n",
    "        '/': {\n",
    "            'request.dispatch': cherrypy.dispatch.MethodDispatcher(),\n",
    "            # 'tools.sessions.on': True\n",
    "        }\n",
    "    }\n",
    "    cherrypy.tree.mount(Server(), '/', conf)\n",
    "    \n",
    "    ip_server_machine = '192.168.1.7'\n",
    "    cherrypy.config.update({'server.socket_host': ip_server_machine})\n",
    "    cherrypy.config.update({'server.socket_port': 8080})\n",
    "    cherrypy.engine.start()\n",
    "    cherrypy.engine.block()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
