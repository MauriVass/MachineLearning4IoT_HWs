{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML4IoT_HW2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2USUbO01JSScSyH+tAh+f",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MauriVass/MachineLearningInIoT_HWs/blob/mauri/HM2/ML4IoT_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N31T3wN-atpG"
      },
      "source": [
        "#Import Data\n",
        "import argparse\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#parser = argparse.ArgumentParser()\n",
        "#parser.add_argument('--model', type=str, required=False, help='model name: MLP, CNN, LSTM', default='MLP')\n",
        "#parser.add_argument('--labels', type=int, required=False, help='model output', default=0)\n",
        "#args = parser.parse_args()\n",
        "\n",
        "#Set a seed to get repricable results\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "#Download and extract the .csv file. The result is cached to avoid to download everytime\n",
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True,\n",
        "    cache_dir='.', cache_subdir='data')\n",
        "csv_path, _ = os.path.splitext(zip_path)\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "#Take the required columns\n",
        "column_indices = [2, 5]\n",
        "columns = df.columns[column_indices]\n",
        "data = df[columns].values.astype(np.float32)\n",
        "\n",
        "#Separate the data in train, validation and test sets\n",
        "n = len(data)\n",
        "train_data = data[0:int(n*0.7)]\n",
        "val_data = data[int(n*0.7):int(n*0.9)]\n",
        "test_data = data[int(n*0.9):]\n",
        "print(f'Total length: {n}, Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}')\n",
        "\n",
        "class WindowGenerator:\n",
        "\tdef __init__(self, mean, std):\n",
        "\t\tself.input_width = 6\n",
        "\t\tself.output_width = 6\n",
        "\t\tself.label_options = 2\n",
        "\t\tself.mean = tf.reshape(tf.convert_to_tensor(mean), [1, 1, 2])\n",
        "\t\tself.std = tf.reshape(tf.convert_to_tensor(std), [1, 1, 2])\n",
        "\n",
        "\tdef split_window(self, features):\n",
        "\t\t#print(1,features.shape)\n",
        "\t\tinputs = features[:, :-self.output_width, :]\n",
        "\t\t#print(2,inputs.shape)\n",
        "\n",
        "\t\tmulti_step = True\n",
        "\t\tif(multi_step is False):\n",
        "\t\t\tlabels = features[:, -self.output_width, :]\n",
        "\t\t\t#print(3,labels.shape)\n",
        "\t\t\tlabels.set_shape([None, self.label_options])\n",
        "\t\t\t#print(5,labels.shape,'\\n\\n')\n",
        "\t\telse:\n",
        "\t\t\tlabels = features[:, -self.output_width:, :]\n",
        "\t\t\t#print(3,labels.shape)\n",
        "\t\t\tlabels.set_shape([None, self.output_width, self.label_options])\n",
        "\t\t\t#print(5,labels.shape,'\\n\\n')\n",
        "\n",
        "\t\t#labels = tf.expand_dims(labels, -1)\n",
        "\n",
        "\t\tinputs.set_shape([None, self.input_width, self.label_options])\n",
        "\t\t#print(4,inputs.shape)\n",
        "\n",
        "\t\treturn inputs, labels\n",
        "\n",
        "\tdef normalize(self, features):\n",
        "\t\tfeatures = (features - self.mean) / (self.std + 1.e-6)\n",
        "\t\treturn features\n",
        "\n",
        "\tdef preprocess(self, features):\n",
        "\t\tinputs, labels = self.split_window(features)\n",
        "\t\tinputs = self.normalize(inputs)\n",
        "\n",
        "\t\treturn inputs, labels\n",
        "\n",
        "\tdef make_dataset(self, data, train):\n",
        "\t\t#The targets is None since the labels are already inside the data\n",
        "\t\tds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "\t\t\t\t\t\tdata=data,\n",
        "\t\t\t\t\t\ttargets=None,\n",
        "\t\t\t\t\t\tsequence_length=self.input_width+self.output_width,\n",
        "\t\t\t\t\t\tsequence_stride=1,\n",
        "\t\t\t\t\t\tbatch_size=32)\n",
        "\t\tds = ds.map(self.preprocess)\n",
        "\t\tds = ds.cache()\n",
        "\t\tif train is True:\n",
        "\t\t\tds = ds.shuffle(100, reshuffle_each_iteration=True)\n",
        "\n",
        "\t\treturn ds\n",
        "\n",
        "\n",
        "#Calculate statistics for normalization\n",
        "mean = train_data.mean(axis=0)\n",
        "std = train_data.std(axis=0)\n",
        "\n",
        "generator = WindowGenerator(mean, std)\n",
        "train_ds = generator.make_dataset(train_data, True)\n",
        "val_ds = generator.make_dataset(val_data, False)\n",
        "test_ds = generator.make_dataset(test_data, False)\n",
        "print(f'Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}')\n",
        "\n",
        "\n",
        "import time\n",
        "if(True):\n",
        "\tfor x,y in train_ds.take(1):\n",
        "\t\tprint(x.shape) #(32,6,2)\n",
        "\t\tprint(y.shape) #(32,6,1 or 2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llWRXlA7PEzB"
      },
      "source": [
        "#print(model.model.metrics_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZpYKVch2qOk"
      },
      "source": [
        "#Train Model\n",
        "!pip install tensorflow_model_optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "\n",
        "class TempHumMAE(keras.metrics.Metric):\n",
        "\tdef __init__(self, name='mean_absolute_error_cust', **kwargs):\n",
        "\t\tsuper().__init__(name, **kwargs)\n",
        "\t\t#initialiaze the variables used to calculate the loss\n",
        "\t\tself.count = self.add_weight(name='count', initializer='zeros')\n",
        "\t\t#The shape [2]('shape=(2,)' is equivalent) is for temperature ad humidity\n",
        "\t\tself.total = self.add_weight(name='total', initializer='zeros', shape=(2,))\n",
        "\n",
        "\t#Called at every batch of data\n",
        "\tdef update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\t\t#print('Prediction',y_pred)\n",
        "\t\t#print('True',y_true)\n",
        "\t\terror = tf.abs(y_pred-y_true)\n",
        "    #Calculate mean over output_width and batch\n",
        "\t\terror = tf.reduce_mean(error, axis=(0,1))#\n",
        "\t\t#print(error)\n",
        "\t\t#You can just use + sign but it is better to use assign_add method\n",
        "\t\tself.total.assign_add(error)\n",
        "\t\tself.count.assign_add(1.)\n",
        "\t\treturn\n",
        "\tdef reset_states(self):\n",
        "\t\tself.count.assign(tf.zeros_like(self.count))\n",
        "\t\tself.total.assign(tf.zeros_like(self.total))\n",
        "\t\treturn\n",
        "\tdef result(self):\n",
        "\t\tresults = tf.math.divide_no_nan(self.total, self.count)\n",
        "\t\treturn results\n",
        "\n",
        "def my_schedule(epoch, lr):\n",
        "\tif epoch < 10:\n",
        "\t\treturn lr\n",
        "\telse:\n",
        "\t\treturn lr * tf.math.exp(-0.1)\n",
        "\n",
        "#https://www.tensorflow.org/tutorials/structured_data/time_series#single_step_models\n",
        "class Model:\n",
        "  def __init__(self,model_type,alpha=1,sparsity=None):\n",
        "    self.alpha = alpha\n",
        "    self.label=2\n",
        "    self.n_output = 1 if self.label < 2 else 2\n",
        "    self.metric = ['mae'] if self.label < 2 else [TempHumMAE()]\n",
        "    self.model_type = model_type\n",
        "    if(model_type=='MLP'):\n",
        "      self.model = self.MLPmodel()\n",
        "    elif(model_type=='CNN'):\n",
        "      self.model = self.CNNmodel(alpha)\n",
        "    elif(model_type=='LSTM'):\n",
        "      self.model = self.LSTMmodel(alpha)\n",
        "\n",
        "    #CALLBACKS\n",
        "    self.callbacks = []\n",
        "    self.checkpoint_path = 'THckp/'\n",
        "    monitor_loss = 'mean_squared_error'\n",
        "    self.model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=self.checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor=monitor_loss,\n",
        "    mode='auto',\n",
        "    save_best_only=True)\n",
        "    self.callbacks.append(self.model_checkpoint_callback)\n",
        "\n",
        "    self.early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=monitor_loss, min_delta=0.05, patience=3, verbose=1, mode='auto',\n",
        "        baseline=None, restore_best_weights=True)\n",
        "    #self.callbacks.append(self.early_stopping)\n",
        "\n",
        "    self.lr_exp = tf.keras.callbacks.LearningRateScheduler(my_schedule, verbose=1)\n",
        "    #self.callbacks.append(self.lr_exp)\n",
        "    self.lr_onplateau = tf.keras.callbacks.ReduceLROnPlateau(monitor=monitor_loss, factor=0.1,\n",
        "        patience=2, min_lr=0.001, verbose=1)\n",
        "    #self.callbacks.append(self.lr_onplateau)\n",
        "\n",
        "    self.sparsity = sparsity\n",
        "    if(self.sparsity is not None):\n",
        "      prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "      self.model = prune_low_magnitude(self.model, **pruning_params)\n",
        "      self.model_sparcity_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
        "      self.callbacks.append(self.model_sparcity_callback)\n",
        "      self.callbacks.append(tfmot.sparsity.keras.PruningSummaries(log_dir='PruningSumm/'))\n",
        "      input_shape = [None, 6, 2]\n",
        "      self.model.build(input_shape)\n",
        "\n",
        "    self.model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError(),\n",
        "                  metrics=[self.metric,tf.keras.losses.MeanSquaredError()])\n",
        "   \n",
        "  def MLPmodel(self):\n",
        "    model = keras.Sequential([\n",
        "          keras.layers.Flatten(),\n",
        "          keras.layers.Dense(int(128*self.alpha), activation='relu'),\n",
        "          keras.layers.Dense(int(128*self.alpha), activation='relu'),\n",
        "          keras.layers.Dense(self.n_output*6),\n",
        "          keras.layers.Reshape([6, 2])\n",
        "        ])\n",
        "    return model\n",
        "  def CNNmodel(self,alpha):\n",
        "    model = keras.Sequential([\n",
        "          keras.layers.Conv1D(filters=int(64*self.alpha),kernel_size=(3,),activation='relu'),\n",
        "          keras.layers.Flatten(),\n",
        "          keras.layers.Dense(int(64*self.alpha), activation='relu'),\n",
        "          keras.layers.Dense(self.n_output*6),\n",
        "          keras.layers.Reshape([6, 2])\n",
        "        ])\n",
        "    return model\n",
        "  def LSTMmodel(self,alpha):\n",
        "    model = keras.Sequential([\n",
        "          keras.layers.LSTM(units=int(64*alpha)),\n",
        "          keras.layers.Flatten(),\n",
        "          keras.layers.Dense(self.n_output*6),\n",
        "          keras.layers.Reshape([6, 2])\n",
        "        ])\n",
        "    return model\n",
        "\n",
        "  def Train(self,train,validation,epoch):\n",
        "    print('\\nCallbacks used:')\n",
        "    if(True):\n",
        "      for c in self.callbacks:\n",
        "        print(c)\n",
        "    print()\n",
        "    history = self.model.fit(train, batch_size=32, epochs=epoch, verbose=1,\n",
        "                        validation_data=validation, validation_freq=2, callbacks=self.callbacks)#\n",
        "    return history\n",
        "\n",
        "  def Test(self, test, best=False):\n",
        "    if(best):\n",
        "      self.model.load_weights(self.checkpoint_path)\n",
        "    error = self.model.evaluate(test, verbose=1)\n",
        "    return error[1]\n",
        "\n",
        "  def SaveModel(self,output,best=False):\n",
        "      output += self.model_type\n",
        "      if(self.alpha!=1):\n",
        "        output += f'alpha{self.alpha}'\n",
        "      if(self.sparsity!=None):\n",
        "        output += f'spars{self.sparsity}'\n",
        "      if(best):\n",
        "        self.model.load_weights(self.checkpoint_path)\n",
        "      if(self.sparsity):\n",
        "        self.Strip()\n",
        "      run_model = tf.function(lambda x: self.model(x))\n",
        "      concrete_func = run_model.get_concrete_function(tf.TensorSpec([1,6,2], tf.float32))\n",
        "      output = output.replace('.','_')\n",
        "      print(f'\\n### Saving model: {output} ###\\n')\n",
        "      self.model.save(output, signatures=concrete_func)\n",
        "      return output\n",
        "      #self.model.save(output)\n",
        "\n",
        "  def Strip(self):\n",
        "    self.model = tfmot.sparsity.keras.strip_pruning(self.model)\n",
        "\n",
        "### MAIN PARAMETERS ###\n",
        "### Model A ###\n",
        "#It can be ['MLP', 'CNN', 'LSTM']\n",
        "model_type = 'MLP'\n",
        "#It can be (0,1]\n",
        "alpha = 0.25\n",
        "#Sparcity increases latency(may be a problem for KS) due to cache misses\n",
        "#it can be (0.3,1) or None(if you don't to use sparsity)\n",
        "sparsity = 0.9\n",
        "### ### ###\n",
        "\n",
        "### Model B ###\n",
        "#It can be ['MLP', 'CNN', 'LSTM']\n",
        "model_type = 'CNN'\n",
        "#It can be (0,1]\n",
        "alpha = 0.07\n",
        "#Sparcity increases latency(may be a problem for KS) due to cache misses\n",
        "#it can be (0.3,1) or None(if you don't to use sparsity)\n",
        "sparsity = 0.7\n",
        "### ### ###\n",
        "\n",
        "pruning_params = {\n",
        "\t'pruning_schedule':\n",
        "\t\ttfmot.sparsity.keras.PolynomialDecay(\n",
        "\t\tinitial_sparsity=0.30,\n",
        "\t\tfinal_sparsity=sparsity,\n",
        "\t\tbegin_step=len(train_ds)*3,\n",
        "\t\tend_step=len(train_ds)*15)}\n",
        "\n",
        "model = Model(model_type,alpha=alpha,sparsity=sparsity)  \n",
        "init = time.time()\n",
        "hist = model.Train(train_ds, val_ds, 20)\n",
        "end = time.time()\n",
        "print(f'{end-init}')\n",
        "\n",
        "best = True\n",
        "if(best is False):\n",
        "\terror = model.Test(test_ds)\n",
        "\ttemp_loss, hum_loss = error\n",
        "\tprint(f'Loss: Temp={temp_loss}, Hum={hum_loss}')\n",
        "\tmodel.SaveModel(f'TH')\n",
        "\tprint('\\n')\n",
        "else:\n",
        "\terror = model.Test(test_ds,best)\n",
        "\ttemp_loss, hum_loss = error\n",
        "\tprint(f'Loss: Temp={temp_loss}, Hum={hum_loss}')\n",
        "\toutput_model = model.SaveModel(f'TH_',True)\n",
        "\n",
        "\n",
        "print(model.model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq8gWhTO23ns"
      },
      "source": [
        "#(not needed in the pipeline)\r\n",
        "# !rm -r THckp/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibDep-r2Y2T_"
      },
      "source": [
        "output_model = 'TH_MLPalpha0_25spars0_9'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VozLiXfT2sTl"
      },
      "source": [
        "#Deployer, Optimizer W_WA\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "def representative_dataset_gen():\n",
        "    for x, _ in train_ds.take(1000):\n",
        "        yield [x]\n",
        "\n",
        "def Optimize(saved_model_dir,quantization,zipping):\n",
        "  converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "  if(quantization=='w'):\n",
        "      print('Only Weight')\n",
        "      #Quantization Weights only\n",
        "      converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "      mini_float = False\n",
        "      if(mini_float):\n",
        "          converter.target_spec.supported_types = [tf.float16]\n",
        "      tflite_model_dir = saved_model_dir + '.tflite_W'\n",
        "  elif(quantization=='wa'):\n",
        "      print('Weight Activation')\n",
        "      #Quantization Weights and Activation\n",
        "      converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "      converter.representative_dataset = representative_dataset_gen\n",
        "      tflite_model_dir = saved_model_dir + 'tflite_WA'\n",
        "  else:\n",
        "      tflite_model_dir = saved_model_dir + '.tflite'\n",
        "  tflite_model = converter.convert()\n",
        "\n",
        "  #Compression\n",
        "  if(zipping is False):\n",
        "      with open(tflite_model_dir, 'wb') as fp:\n",
        "          fp.write(tflite_model)\n",
        "  else:\n",
        "      print('Compression')\n",
        "      import zlib\n",
        "      tflite_model_dir = tflite_model_dir + '.zip'\n",
        "      with open(tflite_model_dir, 'wb') as fp:\n",
        "          tflite_compressed = zlib.compress(tflite_model)#,level=9\n",
        "          fp.write(tflite_compressed)\n",
        "\n",
        "  print('Saving: ', tflite_model_dir)\n",
        "  size_tflite_model = os.path.getsize(tflite_model_dir)\n",
        "  print(f'Tflite Model size: {(size_tflite_model/1024):.2f} kB')\n",
        "  return tflite_model_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0TQ-X92Ohhm"
      },
      "source": [
        "#Optimization for TH Forecasting\r\n",
        "#any -> none\r\n",
        "#w -> only weights\r\n",
        "#wa -> weights and activation (have some problem with the shape/last reshape layer (maybe))\r\n",
        "quantization = 'w' \r\n",
        "zipping = False\r\n",
        "saved_model_dir = output_model\r\n",
        "output_tflite_model = Optimize(saved_model_dir,quantization,zipping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3HR7EG28LCe"
      },
      "source": [
        "#Decompress (not needed in the pipeline)\n",
        "import zlib\n",
        "model_path = output_tflite_model \n",
        "if(model_path.find('zip')<0):\n",
        "  raise KeyError('YOU CAN\\'T DECOMPRESS A NON .zip MODEL')\n",
        "with open(model_path, 'rb') as fp:\n",
        "    model = zlib.decompress(fp.read())\n",
        "    output_mod = model_path[:-4]\n",
        "    file = open(output_mod,'wb')\n",
        "    print('Saving: ',output_mod)\n",
        "    file.write(model)\n",
        "    size_tflite_mod = os.path.getsize(output_mod)\n",
        "    print(f'Tflite Model size: {(size_tflite_mod/1024):.2f} kB')\n",
        "    file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lewFu0qUQ-X"
      },
      "source": [
        "#Test Models\n",
        "import time\n",
        "import tensorflow.lite as tflite\n",
        "\n",
        "saved_model_dir = output_tflite_model\n",
        "if(saved_model_dir.find('zip')>0):\n",
        "  raise KeyError('YOU CAN\\'T TEST A .zip MODEL. (Use zipping=False in Optimize() method)')\n",
        "\n",
        "test_ds = test_ds.unbatch().batch(1)\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=saved_model_dir)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "mae = [0,0]\n",
        "n = 0\n",
        "time_infe = 0\n",
        "#print(test_ds)\n",
        "\n",
        "for x,y in test_ds:\n",
        "  #print(x,y)\n",
        "  input_data = x\n",
        "  y_true = y.numpy()[0]\n",
        "  \n",
        "  ti = time.time()\n",
        "  interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "  interpreter.invoke()\n",
        "  my_output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
        "  time_infe += time.time()-ti\n",
        "\n",
        "  n+=1\n",
        "  #mae[0] += np.abs(y[0] - my_output[0])\n",
        "  #mae[1] += np.abs(y[1] - my_output[1])\n",
        "  error = tf.abs(my_output-y_true)\n",
        "  mae += tf.reduce_mean(error, axis=(0,))\n",
        "\n",
        "  #print(f'Measured: {y[0]}, {y[1]} --- Predicted: {my_output[0]:.2f}, {my_output[1]:.2f} --- MAE: {:.2f}, {np.abs(y[1] - my_output[1]):.2f}')\n",
        "print(f'MAE: temp: {mae[0]/n}, humi: {mae[1]/n}, time: {(time_infe/n)*1000} ms')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gov-umJbtfcN"
      },
      "source": [
        "#        Destination      Origin Folder  (not needed in the pipeline)\n",
        "!zip -r ./th_test.zip   ./th_test1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-PuwROngtbu"
      },
      "source": [
        "!unzip THFmodelCNN.zip ./THFmodelCNN (not needed in the pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGvbPzxD-LXT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}